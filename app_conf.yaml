################
# Application configuration file 
################

# cSpell:disable

# Configuration leverage OmegaConf solvers. See :
# https://omegaconf.readthedocs.io/en/2.3_branch/usage.html#variable-interpolation


paths:
  project : ${oc.env:PWD}
  data_root : ${oc.env:HOME}

#####
# Default configuration (baseline)
####
baseline:
  llm:
    list: ${paths.project}/models_providers.yaml
    default_model: gpt_4omini_openai # gpt_35_azure # mistral_large_edenai 
    cache : sqlite
    cache_path: ${paths.data_root}/llm_cache/langchain.db

    ### 
    # Optional model definitions (you can add your own type): 
    ###
    coder_model : qwen25_coder32_openrouter
    powerful_model : gpt_4_openai
    fast_model : llama31_8_groq
    
  embeddings:
    list: ${paths.project}/models_providers.yaml
    default_model:  minilm_multilingual_local #ada_002_edenai #
    cache: ${paths.data_root}/hf_models
  vector_store:
    default: Chroma
    path: ${paths.data_root}/vector_store
    default_collection: "training_session"
  documents:
    base: ./use_case_data
  monitoring: 
    default:  none
    project: GenAI_demo

  kv_store:
    path: ${paths.data_root}/kv_store

  commands:
    modules:
      - src.ai_core.cli_commands
      - src.ai_extra.cli_commands

  chains:
    root: src.ai_chains
    modules:
      - ${..root}.A_1_joke 
      - ${..root}.B_1_naive_rag_example
      - ${..root}.B_2_self_query
      - ${..root}.C_1_tools_example
      # - ${..root}.C_2_advanced_rag_langgraph
      # - ${..root}.C_3_essay_writer_agent
      
  #### 
  # MCP Servers Configuration
  # Similar to "C:\Users\a184094\AppData\Roaming\Claude\claude_desktop_config.json"
  ####    
  mcpServers:
    filesystem:
        command: npx
        args: 
        - "-y"
        - "@modelcontextprotocol/server-filesystem"
        - ${paths.project}

    pubmed:
        command: uvx
        args: ["--quiet", "pubmedmcp@0.1.3"]
        description: Provides access to PubMed medical research database
        example : "Find relevant studies on alcohol hangover and treatment."
        disabled: true

    playwright:
      command: npx
      args: 
      - "@playwright/mcp@latest"
      - "--headless"
    
    github:
      command: npx
      args:  ["-y", "@modelcontextprotocol/server-github"]
      env:
        GITHUB_PERSONAL_ACCESS_TOKEN: ${oc.env:GITHUB_TOKEN}
      disabled: true

    tavily-mcp: 
      command: npx
      args: [ "-y" ,"tavily-mcp"]
      env: 
        TAVILY_API_KEY : ${oc.env:TAVILY_API_KEY}
    #  disabled: true
      
    sequential-thinking: 
      command: npx
      args: ["-y", "@modelcontextprotocol/server-sequential-thinking"]
      
    ppt: 
      command: uvx
      args: ["--from", "office-powerpoint-mcp-server", "ppt_mcp_server"]


    math:
        command: uv
        args: 
          - run 
          - ${paths.project}/src/mcp_server/math_server.py
        disabled: true
      
    weather:
        command: uv
        args: 
          - run 
          - ${paths.project}/src/mcp_server/weather_server.py
        disabled: false



#### 
# Overridden configurations
# Set by environment variable "BLUEPRINT_CONFIG", or by the 'default' key, or in code
####   

training_local:
  llm:
    default_model:  llama32_3_ollama
  embeddings:
    default_model: artic_22_ollama

training_edenai:
  llm:
    default_model: gpt_4omini_edenai
    cache : memory
  embeddings:
    default_model: ada_002_edenai

training_azure:
  llm:
    default_model: gpt_4omini_azure
  embeddings:
    default_model: ada_002_azure

training_openai:
  llm:
    default_model: gpt_4omini_openai
  embeddings:
    default_model: ada_002_openai

default_config: training_edenai   # can be overidden by 'BLUEPRINT_CONFIG' environment variable
