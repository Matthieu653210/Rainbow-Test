################
# Application configuration file 
################

# cSpell:disable

# Configuration leverage OmegaConf solvers. See :
# https://omegaconf.readthedocs.io/en/2.3_branch/usage.html#variable-interpolation


paths:
  project : ${oc.env:PWD}
  data_root : ${oc.env:HOME}

# Default configuration
baseline:
  llm:
    list: ${paths.project}/models_providers.yaml
    default_model: gpt_4omini_openai # gpt_35_azure # mistral_large_edenai 
    cache : sqlite
    cache_path: ${paths.data_root}/llm_cache/langchain_ecod.db

    # optional model definitions (you can add your own type): 
    coder_model : qwen25_coder32_openrouter
    powerful_model : gpt_4_openai
    fast_model : llama31_8_groq
    
  embeddings:
    list: ${paths.project}/models_providers.yaml
    default_model:  multilingual_MiniLM_local #ada_002_edenai #
    cache: ${paths.data_root}/hf_models
  vector_store:
    default: Chroma
    path: ${paths.data_root}/vector_store
    default_collection: "training_session"
  documents:
    base: ./use_case_data
  monitoring: 
    default:  none
    project: GenAI_demo

  kv_store:
    path: ${paths.data_root}/kv_store

  commands:
    modules:
      - src.ai_core.cli_commands

  chains:
    root: src.ai_chains
    modules:
      - ${..root}.A_1_joke 
      # - ${..root}.B_1_naive_rag_example
      # - ${..root}.B_2_self_query
      - ${..root}.C_1_tools_example
      # - ${..root}.C_2_advanced_rag_langgraph
      # - ${..root}.C_3_essay_writer_agent
      
  mcp_servers:
    - math:
      - command: uv
      - args:
        - run 
        - ${paths.project}/src/mcp_server/math_server.py
      - transport: stdio
    - filesystem:
      - command: npx
      - args:
        - "-y"
        - "@modelcontextprotocol/server-filesystem"
        - ${paths.project}
      - transport: stdio
    # - timeserver: 
    #   - command: npx
    #   - args:
    #     - "-y"
    #     - "@modelcontextprotocol/mcp-server-time"
    #   #- description: Provides current time and timezone conversions
    #   - transport: stdio
    - pubmed:
      - command: uv
      - args: ["tool", "run", "--quiet", "pubmedmcp@0.1.3"]
      - transport: stdio
      #- description: Provides access to PubMed medical research database
      #- example : "Find relevant studies on alcohol hangover and treatment."


 
# Overridden configurations
# Set by environment variable "BLUEPRINT_CONFIG", or by the 'default' key, or in code


training_local:
  llm:
    default_model:  llama32_3_ollama
  embeddings:
    default_model: artic_22_ollama

training_edenai:
  llm:
    default_model: gpt_4omini_edenai
    cache : memory
  embeddings:
    default_model: ada_002_edenai

training_azure:
  llm:
    default_model: gpt_4o_azure
  embeddings:
    default_model: ada_002_azure

training_openai:
  llm:
    default_model: gpt_4omini_openai
  embeddings:
    default_model: ada_002_openai

default_config: training_openai   # can be overidden by 'BLUEPRINT_CONFIG' environment variable
