{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools calling with LangGraph React Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from devtools import debug\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "!export PYTHONPATH=\":./python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from python.ai_core.llm import get_llm\n",
    "from python.ai_core.prompts import def_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-18 14:40:37.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpython.ai_core.llm\u001b[0m:\u001b[36mget_llm\u001b[0m:\u001b[36m418\u001b[0m - \u001b[1mget LLM:'gpt_35_azure' -configurable: False - streaming: False\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_community.llms import EdenAI\n",
    "from langchain_community.tools.edenai import (\n",
    "    EdenAiExplicitImageTool,\n",
    "    EdenAiObjectDetectionTool,\n",
    "    EdenAiParsingIDTool,\n",
    "    EdenAiParsingInvoiceTool,\n",
    "    EdenAiSpeechToTextTool,\n",
    "    EdenAiTextModerationTool,\n",
    "    EdenAiTextToSpeechTool,\n",
    ")\n",
    "\n",
    "# llm = EdenAI(\n",
    "#     feature=\"text\", provider=\"openai\", params={\"temperature\": 0.2, \"max_tokens\": 250}\n",
    "# )\n",
    "llm = get_llm(\"gpt_35_azure\")\n",
    "#llm = get_llm(\"gpt_35_openai\")\n",
    "\n",
    "# Define lit of tools\n",
    "\n",
    "tools = [\n",
    "    EdenAiTextModerationTool(providers=[\"openai\"], language=\"en\"),\n",
    "    EdenAiObjectDetectionTool(providers=[\"google\", \"api4ai\"]),\n",
    "    EdenAiTextToSpeechTool(providers=[\"amazon\"], language=\"en\", voice=\"MALE\"),\n",
    "    EdenAiExplicitImageTool(providers=[\"amazon\", \"google\"]),\n",
    "    EdenAiSpeechToTextTool(providers=[\"amazon\"]),\n",
    "    EdenAiParsingIDTool(providers=[\"amazon\", \"klippa\"], language=\"en\"),\n",
    "    EdenAiParsingInvoiceTool(providers=[\"amazon\", \"google\"], language=\"en\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Select and execute and Eden.AI provided tool with React agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the edenai_explicit_content_detection_text tool to check if the text contains explicit content. If it does, I can use the same tool to identify the type of explicit content. Then, I can use the edenai_text_to_speech tool to convert the text into speech.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. 'i want to slap you'\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mOops, I made a mistake. I should have used the edenai_speech_to_text tool to convert the text into speech.\n",
      "\n",
      "Action:\n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_speech_to_text\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. URL to audio file generated by edenai_speech_to_text\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_speech_to_text is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mOops, I made another mistake. I should have used the edenai_text_to_speech tool to convert the text into speech.\n",
      "\n",
      "Action:\n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. 'i want to slap you'\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI need to use the edenai_text_to_speech tool first to convert the text into speech, and then use the edenai_explicit_content_detection_text tool to check if the speech contains explicit content. If it does, I can use the same tool to identify the type of explicit content.\n",
      "\n",
      "Action:\n",
      "1. edenai_text_to_speech\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. URL to audio file generated by edenai_text_to_speech\n",
      "\u001b[0m1. edenai_text_to_speech\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher) is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI made another mistake. I should have used the edenai_speech_to_text tool to convert the speech back into text, and then use the edenai_explicit_content_detection_text tool to check if the text contains explicit content. If it does, I can use the same tool to identify the type of explicit content.\n",
      "\n",
      "Action:\n",
      "1. edenai_text_to_speech\n",
      "2. edenai_speech_to_text\n",
      "3. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. URL to audio file generated by edenai_text_to_speech\n",
      "3. Text generated by edenai_speech_to_text\n",
      "\u001b[0m1. edenai_text_to_speech\n",
      "2. edenai_speech_to_text\n",
      "3. edenai_explicit_content_detection_text (if likelihood is 3 or higher) is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI need to use the edenai_explicit_content_detection_text tool first to check if the text contains explicit content. If it does, I can use the same tool to identify the type of explicit content. Then, I can use the edenai_text_to_speech tool to convert the text into speech.\n",
      "\n",
      "Action:\n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. Text generated by edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. 'i want to slap you'\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI made another mistake. I should have used the edenai_text_to_speech tool first to convert the text into speech, and then use the edenai_explicit_content_detection_text tool to check if the speech contains explicit content. If it does, I can use the same tool to identify the type of explicit content.\n",
      "\n",
      "Action:\n",
      "1. edenai_text_to_speech\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. URL to audio file generated by edenai_text_to_speech\n",
      "\u001b[0m1. edenai_text_to_speech\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher) is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing]."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `I need to use the edenai_image_explicit_content_detection tool to check if there is any explicit content in the image.`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:1370\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1370\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:463\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}):\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:3174\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   3169\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3170\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   3171\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3172\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3173\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3174\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:3161\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   3156\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3157\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   3158\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3159\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3160\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3161\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   3162\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3163\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   3164\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   3165\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3166\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:2003\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 2003\u001b[0m     chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:3123\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3121\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[0;32m-> 3123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[1;32m   3124\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1239\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1239\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:853\u001b[0m, in \u001b[0;36mRunnable.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;124;03mDefault implementation of stream, which calls invoke.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;124;03mSubclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;124;03m    The output of the Runnable.\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:183\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1734\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1731\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1732\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1733\u001b[0m         Output,\n\u001b[0;32m-> 1734\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1737\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1742\u001b[0m     )\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/runnables/config.py:379\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:184\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 184\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    188\u001b[0m         config,\n\u001b[1;32m    189\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:237\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03mThe return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    Structured output.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain/agents/output_parsers/react_single_input.py:75\u001b[0m, in \u001b[0;36mReActSingleInputOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*?)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     77\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n\u001b[1;32m     78\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m     79\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m     )\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*Action\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*Input\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL\n\u001b[1;32m     83\u001b[0m ):\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: `I need to use the edenai_image_explicit_content_detection tool to check if there is any explicit content in the image.`",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m agent \u001b[38;5;241m=\u001b[39m create_react_agent(llm, tools, prompt)\n\u001b[1;32m     13\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(agent\u001b[38;5;241m=\u001b[39magent, tools\u001b[38;5;241m=\u001b[39mtools, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:1636\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1636\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1644\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1645\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1646\u001b[0m         )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:1342\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1335\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1339\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1340\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1342\u001b[0m         [\n\u001b[1;32m   1343\u001b[0m             a\n\u001b[1;32m   1344\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1345\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1346\u001b[0m                 color_mapping,\n\u001b[1;32m   1347\u001b[0m                 inputs,\n\u001b[1;32m   1348\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1349\u001b[0m                 run_manager,\n\u001b[1;32m   1350\u001b[0m             )\n\u001b[1;32m   1351\u001b[0m         ]\n\u001b[1;32m   1352\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:1342\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1335\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1339\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1340\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1342\u001b[0m         [\n\u001b[1;32m   1343\u001b[0m             a\n\u001b[1;32m   1344\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1345\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1346\u001b[0m                 color_mapping,\n\u001b[1;32m   1347\u001b[0m                 inputs,\n\u001b[1;32m   1348\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1349\u001b[0m                 run_manager,\n\u001b[1;32m   1350\u001b[0m             )\n\u001b[1;32m   1351\u001b[0m         ]\n\u001b[1;32m   1352\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genai-blueprint-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:1381\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[0;32m-> 1381\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1382\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn output parsing error occurred. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1386\u001b[0m     )\n\u001b[1;32m   1387\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `I need to use the edenai_image_explicit_content_detection tool to check if there is any explicit content in the image.`"
     ]
    }
   ],
   "source": [
    "input_ = \"\"\"i have this text : 'i want to slap you' \n",
    "first : i want to know if this text contains explicit content or not .\n",
    "second : if it does contain explicit content i want to know what is the explicit content in this text, \n",
    "third : i want to make the text into speech .\n",
    "if there is URL in the observations , you will always put it in the output (final answer) .\n",
    "\"\"\"\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "response = agent_executor.invoke({\"input\": input_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Same with Tool Calling Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Select and execute and Eden.AI provided tool with React agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the edenai_explicit_content_detection_text tool to check if the text contains explicit content. If it does, I can use the same tool to identify the type of explicit content. Then, I can use the edenai_text_to_speech tool to convert the text into speech.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. 'i want to slap you'\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mOops, I made a mistake. I should have used the edenai_speech_to_text tool to convert the text into speech. Let me try again.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_speech_to_text\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. URL to audio file generated by edenai_speech_to_text\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_speech_to_text is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mOops, I made another mistake. I should have used the edenai_text_to_speech tool to convert the text into speech. Let me try again.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. 'i want to slap you'\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI made another mistake. I should have used the edenai_text_to_speech tool with the URL of the text as input. Let me try again.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. URL to audio file generated by edenai_text_to_speech with 'i want to slap you' as input\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI made another mistake. I should have used the edenai_text_to_speech tool with the text as input, not the URL of the audio file. Let me try again.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. 'i want to slap you'\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI need to use the edenai_text_to_speech tool with the text as input, and then use the URL of the audio file generated as the final output.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. 'i want to slap you'\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI made another mistake. I should have used the edenai_text_to_speech tool with the text as input, and then used the URL of the audio file generated as the final output.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. URL to audio file generated by edenai_text_to_speech with 'i want to slap you' as input\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI made another mistake. I should have used the edenai_text_to_speech tool with the text as input, and then used the URL of the audio file generated as the final output.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. 'i want to slap you'\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI need to use the edenai_text_to_speech tool with the text as input, and then use the URL of the audio file generated as the final output.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. URL to audio file generated by edenai_text_to_speech with 'i want to slap you' as input\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI made another mistake. I should have used the edenai_text_to_speech tool with the text as input, and then used the URL of the audio file generated as the final output.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. 'i want to slap you'\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI need to use the edenai_text_to_speech tool with the text as input, and then use the URL of the audio file generated as the final output.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. URL to audio file generated by edenai_text_to_speech with 'i want to slap you' as input\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI need to use the edenai_text_to_speech tool with the text as input, and then use the URL of the audio file generated as the final output.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. 'i want to slap you'\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI need to use the edenai_text_to_speech tool with the text as input, and then use the URL of the audio file generated as the final output.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. URL to audio file generated by edenai_text_to_speech with 'i want to slap you' as input\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI need to use the edenai_text_to_speech tool with the text as input, and then use the URL of the audio file generated as the final output.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. 'i want to slap you'\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3mI need to use the edenai_text_to_speech tool with the text as input, and then use the URL of the audio file generated as the final output.\n",
      "\n",
      "Action: \n",
      "1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech\n",
      "\n",
      "Action Input:\n",
      "1. 'i want to slap you'\n",
      "2. 'i want to slap you' (if likelihood is 3 or higher)\n",
      "3. URL to audio file generated by edenai_text_to_speech with 'i want to slap you' as input\n",
      "\u001b[0m1. edenai_explicit_content_detection_text\n",
      "2. edenai_explicit_content_detection_text (if likelihood is 3 or higher)\n",
      "3. edenai_text_to_speech is not a valid tool, try one of [edenai_explicit_content_detection_text, edenai_object_detection, edenai_text_to_speech, edenai_image_explicit_content_detection, edenai_speech_to_text, edenai_identity_parsing, edenai_invoice_parsing].\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Make sure to use the tavily_search_results_json tool for information.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Construct the Tools agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "\n",
    "response = agent_executor.invoke({\"input\": input_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Same with LangGraph React Implementation (actually using tools)\n",
    "\n",
    "Does not work yet with eden api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# langgraph \"create_react_agent\"  is similar to langchain \"create_tool_calling_agent\"AgentExecutor\"AgentExecutor\"AgentExecutor\n",
    "# Don't confuse with legacy lanchain \"create_react_agent\"\n",
    "\n",
    "def is_obscene(input: str) -> bool:\n",
    "    \"check if the input string is obscene or not\"\n",
    "    return False\n",
    "\n",
    "\n",
    "# DOES NOT WORK with Edenai tools...\n",
    "\n",
    "# tools = [is_obscene]  # This work !\n",
    "\n",
    "graph = create_react_agent(llm, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "i have this text : 'i want to slap you' \n",
      "first : i want to know if this text contains explicit content or not .\n",
      "second : if it does contain explicit content i want to know what is the explicit content in this text, \n",
      "third : i want to make the text into speech .\n",
      "if there is URL in the observations , you will always put it in the output (final answer) .\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure, I can help you with that. To achieve this, we can use the following functions from the `functions` namespace:\n",
      "\n",
      "- `edenai_explicit_content_detection_text`\n",
      "- `edenai_text_to_speech`\n",
      "\n",
      "Here's an example code snippet that you can use:\n",
      "\n",
      "```javascript\n",
      "const { edenai_explicit_content_detection_text, edenai_text_to_speech } = require('./path/to/functions');\n",
      "\n",
      "const text = 'i want to slap you';\n",
      "\n",
      "// Check if the text contains explicit content\n",
      "edenai_explicit_content_detection_text({ __arg1: text })\n",
      "  .then((result) => {\n",
      "    if (result.nsfw_likelihood >= 3) {\n",
      "      // If the text contains explicit content, get the type of explicit content\n",
      "      console.log(`The text contains ${result.nsfw_class} content.`);\n",
      "    } else {\n",
      "      console.log('The text does not contain explicit content.');\n",
      "    }\n",
      "  })\n",
      "  .catch((error) => {\n",
      "    console.error(error);\n",
      "  });\n",
      "\n",
      "// Convert the text to speech\n",
      "edenai_text_to_speech({ __arg1: text })\n",
      "  .then((result) => {\n",
      "    console.log(`The speech URL is: ${result}`);\n",
      "  })\n",
      "  .catch((error) => {\n",
      "    console.error(error);\n",
      "  });\n",
      "```\n",
      "\n",
      "Note that the `edenai_explicit_content_detection_text` function returns an object with a `nsfw_likelihood` property that indicates the likelihood of the text containing explicit content, and a `nsfw_class` property that indicates the type of explicit content if the likelihood is equal or higher than 3.\n",
      "\n",
      "Also, the `edenai_text_to_speech` function returns a string representing the URL of the audio file.\n"
     ]
    }
   ],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", input_)]}\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-training-GvhVNXsu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
