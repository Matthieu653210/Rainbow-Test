{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# fmt:off\n",
    "_ = [sys.path.append(str(path)) for path in [Path.cwd(), Path.cwd().parent, Path.cwd().parent / \"python\"] if str(path) not in sys.path] #fmt:on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "from devtools import debug\n",
    "from langchain_community.llms.edenai import EdenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from python.ai_core.llm import get_llm\n",
    "\n",
    "llm = get_llm()\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "debug(structured_llm.invoke(\"Tell me a joke about cats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "from langchain_community.chat_models.edenai import ChatEdenAI\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add])\n",
    "\n",
    "query = \"What is 11 + 11?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "debug(ai_msg)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "r = llm_with_tools.invoke(messages)\n",
    "\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.ai_core.llm import get_llm\n",
    "\n",
    "llm_oai = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm_groq = ChatGroq(model=\"lLama3-70b-8192\")\n",
    "llm_eden = EdenAI(\n",
    "    feature=\"text\",\n",
    "    provider=\"openai\",\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    ")\n",
    "\n",
    "llm = get_llm(llm_id=\"llama3_8_deepinfra\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([add])\n",
    "llm_with_tools.invoke(\"What is 45 +  99 ?\").tool_calls  # type: ignore # works\n",
    "\n",
    "# llm_with_tools = llm_eden.bind_tools([add]).tool_calls   # AttributeError: 'EdenAI' object has no attribute 'bind_tools'\n",
    "# llm_with_tools = llm_groq.bind_tools([add]).tool_calls   AttributeError: 'ChatGroq' object has no attribute 'tool_calls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Enum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFunnyLevel\u001b[39;00m(\u001b[43mEnum\u001b[49m):\n\u001b[1;32m      5\u001b[0m     very_funny\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m     not_so \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Enum' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class FunnyLevel(Enum):\n",
    "    very_funny= 0\n",
    "    not_so = 1\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    funny_level : FunnyLevel = Field(description=\"Eval how the joke is funny\")\n",
    "    \n",
    "\n",
    "\n",
    "structured_llm = llm_oai.with_structured_output(Joke)\n",
    "debug(structured_llm.invoke(\"Tell me a joke about cats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm_eden.with_structured_output(Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "from langchain_community.chat_models.edenai import ChatEdenAI\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add])\n",
    "\n",
    "query = \"What is 11 + 11?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "r = llm_with_tools.invoke(messages)\n",
    "\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful Search Assistant\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tools = [add]\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)  # type: ignore\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)  # type: ignore\n",
    "\n",
    "r = agent_executor.invoke({\"input\": \"what is 12  + 100\"})\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_community.llms import EdenAI\n",
    "from langchain_community.tools.edenai import (\n",
    "    EdenAiExplicitImageTool,\n",
    "    EdenAiObjectDetectionTool,\n",
    "    EdenAiParsingIDTool,\n",
    "    EdenAiParsingInvoiceTool,\n",
    "    EdenAiSpeechToTextTool,\n",
    "    EdenAiTextModerationTool,\n",
    "    EdenAiTextToSpeechTool,\n",
    ")\n",
    "\n",
    "llm = EdenAI(\n",
    "    feature=\"text\", provider=\"openai\", params={\"temperature\": 0.2, \"max_tokens\": 250}\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    EdenAiTextModerationTool(providers=[\"openai\"], language=\"en\"),\n",
    "    EdenAiObjectDetectionTool(providers=[\"google\", \"api4ai\"]),\n",
    "    EdenAiTextToSpeechTool(providers=[\"amazon\"], language=\"en\", voice=\"MALE\"),\n",
    "    EdenAiExplicitImageTool(providers=[\"amazon\", \"google\"]),\n",
    "    EdenAiSpeechToTextTool(providers=[\"amazon\"]),\n",
    "    EdenAiParsingIDTool(providers=[\"amazon\", \"klippa\"], language=\"en\"),\n",
    "    EdenAiParsingInvoiceTool(providers=[\"amazon\", \"google\"], language=\"en\"),\n",
    "]\n",
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = \"\"\"i have this text : 'i want to slap you' \n",
    "first : i want to know if this text contains explicit content or not .\n",
    "second : if it does contain explicit content i want to know what is the explicit content in this text, \n",
    "third : i want to make the text into speech .\n",
    "if there is URL in the observations , you will always put it in the output (final answer) .\n",
    "\"\"\"\n",
    "result = agent_chain(input_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-training-GvhVNXsu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
