{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# fmt:off\n",
    "_ = [sys.path.append(str(path)) for path in [Path.cwd(), Path.cwd().parent, Path.cwd().parent / \"python\"] if str(path) not in sys.path] #fmt:on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "from devtools import debug\n",
    "from langchain_community.llms.edenai import EdenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from python.ai_core.llm import get_llm\n",
    "\n",
    "llm = get_llm()\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "debug(structured_llm.invoke(\"Tell me a joke about cats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "from langchain_community.chat_models.edenai import ChatEdenAI\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add])\n",
    "\n",
    "query = \"What is 11 + 11?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "r = llm_with_tools.invoke(messages)\n",
    "\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.ai_core.llm import get_llm\n",
    "\n",
    "llm_oai = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm_groq = ChatGroq(model=\"lLama3-70b-8192\")\n",
    "llm_eden = EdenAI(\n",
    "    feature=\"text\",\n",
    "    provider=\"openai\",\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    ")\n",
    "\n",
    "llm = get_llm(llm_id=\"llama3_8_deepinfra\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([add])\n",
    "llm_with_tools.invoke(\"What is 45 +  99 ?\").tool_calls  # type: ignore # works\n",
    "\n",
    "# llm_with_tools = llm_eden.bind_tools([add]).tool_calls   # AttributeError: 'EdenAI' object has no attribute 'bind_tools'\n",
    "# llm_with_tools = llm_groq.bind_tools([add]).tool_calls   AttributeError: 'ChatGroq' object has no attribute 'tool_calls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "\n",
    "structured_llm = llm_oai.with_structured_output(Joke)\n",
    "debug(structured_llm.invoke(\"Tell me a joke about cats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm_eden.with_structured_output(Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43442/2384772665.py:34 <module>\n",
      "    r: AIMessage(\n",
      "        content='The sum of 11 and 11 is 22.',\n",
      "        response_metadata={\n",
      "            'openai': {\n",
      "                'status': 'success',\n",
      "                'generated_text': 'The sum of 11 and 11 is 22.',\n",
      "                'message': [\n",
      "                    {\n",
      "                        'role': 'user',\n",
      "                        'message': 'What is 11 + 11?',\n",
      "                        'tools': [\n",
      "                            {\n",
      "                                'name': 'add',\n",
      "                                'description': (\n",
      "                                    'Adds a and b.\\n'\n",
      "                                    '\\n'\n",
      "                                    '    Args:\\n'\n",
      "                                    '        a: first int\\n'\n",
      "                                    '        b: second int'\n",
      "                                ),\n",
      "                                'parameters': {\n",
      "                                    'type': 'object',\n",
      "                                    'properties': {\n",
      "                                        'a': {\n",
      "                                            'type': 'integer',\n",
      "                                        },\n",
      "                                        'b': {\n",
      "                                            'type': 'integer',\n",
      "                                        },\n",
      "                                    },\n",
      "                                    'required': ['a', 'b'],\n",
      "                                },\n",
      "                            },\n",
      "                        ],\n",
      "                        'tool_calls': None,\n",
      "                    },\n",
      "                    {\n",
      "                        'role': 'assistant',\n",
      "                        'message': 'The sum of 11 and 11 is 22.',\n",
      "                        'tools': None,\n",
      "                        'tool_calls': [],\n",
      "                    },\n",
      "                ],\n",
      "                'cost': 6.3e-05,\n",
      "            },\n",
      "        },\n",
      "        id='run-f189e720-798b-4dcc-8bd1-bd0a583bf7cf-0',\n",
      "    ) (AIMessage)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The sum of 11 and 11 is 22.', response_metadata={'openai': {'status': 'success', 'generated_text': 'The sum of 11 and 11 is 22.', 'message': [{'role': 'user', 'message': 'What is 11 + 11?', 'tools': [{'name': 'add', 'description': 'Adds a and b.\\n\\n    Args:\\n        a: first int\\n        b: second int', 'parameters': {'type': 'object', 'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b']}}], 'tool_calls': None}, {'role': 'assistant', 'message': 'The sum of 11 and 11 is 22.', 'tools': None, 'tool_calls': []}], 'cost': 6.3e-05}}, id='run-f189e720-798b-4dcc-8bd1-bd0a583bf7cf-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from devtools import debug\n",
    "from langchain_community.chat_models.edenai import ChatEdenAI\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add])\n",
    "\n",
    "query = \"What is 11 + 11?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "r = llm_with_tools.invoke(messages)\n",
    "\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tcl/.cache/pypoetry/virtualenvs/genai-training-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_community/chat_models/edenai.py:611: UserWarning: stream: Tool use is not yet supported in streaming mode.\n",
      "  warnings.warn(\"stream: Tool use is not yet supported in streaming mode.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 12, 'b': 100}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m112\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tcl/.cache/pypoetry/virtualenvs/genai-training-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_community/chat_models/edenai.py:611: UserWarning: stream: Tool use is not yet supported in streaming mode.\n",
      "  warnings.warn(\"stream: Tool use is not yet supported in streaming mode.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe sum of 12 and 100 is 112.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "/tmp/ipykernel_43442/1377134187.py:31 <module>\n",
      "    r: {\n",
      "        'input': 'what is 12  + 100',\n",
      "        'output': 'The sum of 12 and 100 is 112.',\n",
      "    } (dict) len=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 12  + 100', 'output': 'The sum of 12 and 100 is 112.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful Search Assistant\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tools = [add]\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)  # type: ignore\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)  # type: ignore\n",
    "\n",
    "r = agent_executor.invoke({\"input\": \"what is 12  + 100\"})\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tcl/.cache/pypoetry/virtualenvs/genai-training-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_community.llms import EdenAI\n",
    "from langchain_community.tools.edenai import (\n",
    "    EdenAiExplicitImageTool,\n",
    "    EdenAiObjectDetectionTool,\n",
    "    EdenAiParsingIDTool,\n",
    "    EdenAiParsingInvoiceTool,\n",
    "    EdenAiSpeechToTextTool,\n",
    "    EdenAiTextModerationTool,\n",
    "    EdenAiTextToSpeechTool,\n",
    ")\n",
    "\n",
    "llm = EdenAI(\n",
    "    feature=\"text\", provider=\"openai\", params={\"temperature\": 0.2, \"max_tokens\": 250}\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    EdenAiTextModerationTool(providers=[\"openai\"], language=\"en\"),\n",
    "    EdenAiObjectDetectionTool(providers=[\"google\", \"api4ai\"]),\n",
    "    EdenAiTextToSpeechTool(providers=[\"amazon\"], language=\"en\", voice=\"MALE\"),\n",
    "    EdenAiExplicitImageTool(providers=[\"amazon\", \"google\"]),\n",
    "    EdenAiSpeechToTextTool(providers=[\"amazon\"]),\n",
    "    EdenAiParsingIDTool(providers=[\"amazon\", \"klippa\"], language=\"en\"),\n",
    "    EdenAiParsingInvoiceTool(providers=[\"amazon\", \"google\"], language=\"en\"),\n",
    "]\n",
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tcl/.cache/pypoetry/virtualenvs/genai-training-2X6HL8i2-py3.10/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m We should use edenai_explicit_content_detection_text to check if the text contains explicit content. If it does, we should use edenai_text_to_speech to convert the text into speech.\n",
      "Action: edenai_explicit_content_detection_text\n",
      "Action Input: 'i want to slap you'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mnsfw_likelihood: 4\n",
      "\"sexual\": 1\n",
      "\"hate\": 1\n",
      "\"harassment\": 4\n",
      "\"self-harm\": 1\n",
      "\"sexual/minors\": 1\n",
      "\"hate/threatening\": 1\n",
      "\"violence/graphic\": 1\n",
      "\"self-harm/intent\": 1\n",
      "\"self-harm/instructions\": 1\n",
      "\"harassment/threatening\": 1\n",
      "\"violence\": 4\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The text contains explicit content, specifically related to sexual harassment and violence.\n",
      "Action: edenai_text_to_speech\n",
      "Action Input: 'i want to slap you'\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mhttps://d14uq1pz7dzsdq.cloudfront.net/644d5e31-1a6b-4715-9617-9e7f6c1d68d8_.mp3?Expires=1718872722&Signature=TUAfFnp5gg7Ig~AAt0hKI3sXa9hnJ6U1hBrcq5pXpcZg8GsVVZmCLLJmEuDAARoPPTS6eYUbe305sg0J9hVpYZTuK6Q9RmfXvRxmjdyFcHkpaWmfnFW8PUgPk1GjkVceIwaCa-XLi1VvnkzkMubdDzJVYOfqF7mI355f8-vd749Ltv66Kr2kH7~TeNvF3zVz0Z7wFFetRCBPvUMeBXMzv7DV6SvT-5p6VWTzSZBWnvubki~Kyv6cPfkj~Mkt3sVjpE~cTFgr9H2ACe4ilz70Q-eoOi9QYgieUHW-lA3pi1hzgMFoc-cg6AalKtV2hidGsG7BVXy2h1OOwLd2YHDDIA__&Key-Pair-Id=K1F55BTI9AHGIK\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The text has been successfully converted into speech.\n",
      "Final Answer: The text contains explicit content related to sexual harassment and violence. The text has been successfully converted into speech and the URL for the audio file is provided.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_ = \"\"\"i have this text : 'i want to slap you' \n",
    "first : i want to know if this text contains explicit content or not .\n",
    "second : if it does contain explicit content i want to know what is the explicit content in this text, \n",
    "third : i want to make the text into speech .\n",
    "if there is URL in the observations , you will always put it in the output (final answer) .\n",
    "\"\"\"\n",
    "result = agent_chain(input_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-training-GvhVNXsu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
