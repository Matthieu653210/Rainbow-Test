{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "!export PYTHONPATH=\":./python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 : provide instruction in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "# IMPORTANT : select Pydantic V1\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-03 16:01:07.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpython.ai_core.llm\u001b[0m:\u001b[36mget_llm\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mget LLM : gpt_4o_edenai - configurable: True\u001b[0m\n",
      "\u001b[32m2024-07-03 16:01:07.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpython.ai_core.llm\u001b[0m:\u001b[36mget_configurable\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1mCannot load gemini_pro_google: No module named 'langchain_google_vertexai'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_141811/3804957977.py:38 <module>\n",
      "    r: Joke(\n",
      "        the_joke='Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!',\n",
      "        explanation=(\n",
      "            \"The joke is funny because it plays on the double meaning of 'mouse'—a computer mouse and the small rodent\"\n",
      "            ' that cats like to chase.'\n",
      "        ),\n",
      "        rate=4.0,\n",
      "    ) (Joke)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(the_joke='Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!', explanation=\"The joke is funny because it plays on the double meaning of 'mouse'—a computer mouse and the small rodent that cats like to chase.\", rate=4.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The usual \"tell me a joke\" LLM call.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "\n",
    "from python.ai_core.llm import get_llm\n",
    "from python.ai_core.prompts import def_prompt\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    the_joke: str = Field(description=\"a good joke\")\n",
    "    explanation: str = Field(description=\"explain why it's funny\")\n",
    "    rate: float = Field(description=\"rate how the joke is funny between 0 and 5\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt_with_format = \"\"\"\n",
    "    tell me  a joke on {topic}     \n",
    "    --- \n",
    "    {format_instructions}\"\"\"\n",
    "\n",
    "structured_prompt = def_prompt(user=prompt_with_format).partial(\n",
    "    format_instructions=parser.get_format_instructions(),\n",
    ")\n",
    "\n",
    "LLM_ID = \"gpt_4o_edenai\"\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "structured_joke = structured_prompt | get_llm(llm_id=LLM_ID) | parser\n",
    "\n",
    "r = structured_joke.invoke({\"topic\": \"cat\"})\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_141811/2639052080.py:1 <module>\n",
      "    structured_prompt: ChatPromptTemplate(\n",
      "        input_variables=['topic'],\n",
      "        partial_variables={\n",
      "            'format_instructions': (\n",
      "                'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n'\n",
      "                '\\n'\n",
      "                'As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strin'\n",
      "                'gs\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\n'\n",
      "                'the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"propertie'\n",
      "                's\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n'\n",
      "                '\\n'\n",
      "                'Here is the output schema:\\n'\n",
      "                '```\\n'\n",
      "                '{\"properties\": {\"the_joke\": {\"title\": \"The Joke\", \"description\": \"a good joke\", \"type\": \"string\"}, \"e'\n",
      "                'xplanation\": {\"title\": \"Explanation\", \"description\": \"explain why it\\'s funny\", \"type\": \"string\"}, \"ra'\n",
      "                'te\": {\"title\": \"Rate\", \"description\": \"rate how the joke is funny between 0 and 5\", \"type\": \"number\"}'\n",
      "                '}, \"required\": [\"the_joke\", \"explanation\", \"rate\"]}\\n'\n",
      "                '```'\n",
      "            ),\n",
      "        },\n",
      "        messages=[\n",
      "            HumanMessagePromptTemplate(\n",
      "                prompt=PromptTemplate(\n",
      "                    input_variables=[\n",
      "                        'format_instructions',\n",
      "                        'topic',\n",
      "                    ],\n",
      "                    template=(\n",
      "                        '\\n'\n",
      "                        'tell me  a joke on {topic}     \\n'\n",
      "                        '--- \\n'\n",
      "                        '{format_instructions}'\n",
      "                    ),\n",
      "                ),\n",
      "            ),\n",
      "        ],\n",
      "    ) (ChatPromptTemplate) len=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['topic'], partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"the_joke\": {\"title\": \"The Joke\", \"description\": \"a good joke\", \"type\": \"string\"}, \"explanation\": {\"title\": \"Explanation\", \"description\": \"explain why it\\'s funny\", \"type\": \"string\"}, \"rate\": {\"title\": \"Rate\", \"description\": \"rate how the joke is funny between 0 and 5\", \"type\": \"number\"}}, \"required\": [\"the_joke\", \"explanation\", \"rate\"]}\\n```'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'topic'], template='\\ntell me  a joke on {topic}     \\n--- \\n{format_instructions}'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug(structured_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tell me  a joke on cat     \n",
      "--- \n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"the_joke\": {\"title\": \"The Joke\", \"description\": \"a good joke\", \"type\": \"string\"}, \"explanation\": {\"title\": \"Explanation\", \"description\": \"explain why it's funny\", \"type\": \"string\"}, \"rate\": {\"title\": \"Rate\", \"description\": \"rate how the joke is funny between 0 and 5\", \"type\": \"number\"}}, \"required\": [\"the_joke\", \"explanation\", \"rate\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# You can have a look at the generated prompt:\n",
    "print(structured_prompt.invoke({\"topic\": \"cat\"}).messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method #2 : Use \"with_structured_output\"  (bases on function calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-03 14:05:54.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpython.ai_core.llm\u001b[0m:\u001b[36mget_llm\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mget LLM : gpt_35_edenai - configurable: True\u001b[0m\n",
      "\u001b[32m2024-07-03 14:05:55.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpython.ai_core.llm\u001b[0m:\u001b[36mget_configurable\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1mCannot load gemini_pro_google: No module named 'langchain_google_vertexai'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_141811/3512315679.py:4 <module>\n",
      "    chain.invoke(({\"topic\": \"cat\"})): Joke(\n",
      "        the_joke='Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!',\n",
      "        explanation=(\n",
      "            'This joke is funny because it plays on the common association of cats chasing mice. The twist of the cat '\n",
      "            'sitting on the computer to watch the mouse adds a humorous element.'\n",
      "        ),\n",
      "        rate=4.5,\n",
      "    ) (Joke)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(the_joke='Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!', explanation='This joke is funny because it plays on the common association of cats chasing mice. The twist of the cat sitting on the computer to watch the mouse adds a humorous element.', rate=4.5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"tell me  a joke on {topic}\"\n",
    "\n",
    "chain = def_prompt(prompt) | get_llm().with_structured_output(Joke)\n",
    "debug(chain.invoke(({\"topic\": \"cat\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Assignement (Optional)\n",
    "Rate the above joke.\n",
    "Use https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/types/enum/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class JokeRater(Enum):\n",
    "    NOT_SO_GOOD = 0\n",
    "    GOOD = 1\n",
    "    VERY_GOOD = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-training-2X6HL8i2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
