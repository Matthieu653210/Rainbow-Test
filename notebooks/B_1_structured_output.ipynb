{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "!export PYTHONPATH=\":./python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 : provide instruction in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "# IMPORTANT : select Pydantic V1\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-04 10:52:43.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpython.ai_core.llm\u001b[0m:\u001b[36mget_llm\u001b[0m:\u001b[36m319\u001b[0m - \u001b[1mget LLM:'gpt_4omini_edenai' -configurable: False - streaming: False\u001b[0m\n",
      "\u001b[32m2024-09-04 10:52:43.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpython.ai_core.cache\u001b[0m:\u001b[36mset_cache\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mLLM cache : SQLiteCache\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_378732/4055731540.py:36 <module>\n",
      "    r: Joke(\n",
      "        the_joke='Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!',\n",
      "        explanation=(\n",
      "            \"This joke is funny because it plays on the double meaning of 'mouse'—the computer accessory and the small\"\n",
      "            ' animal that cats typically chase. The image of a cat being interested in a computer adds a humorous twis'\n",
      "            't.'\n",
      "        ),\n",
      "        rate=4.0,\n",
      "    ) (Joke)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(the_joke='Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!', explanation=\"This joke is funny because it plays on the double meaning of 'mouse'—the computer accessory and the small animal that cats typically chase. The image of a cat being interested in a computer adds a humorous twist.\", rate=4.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The usual \"tell me a joke\" LLM call.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "\n",
    "from python.ai_core.llm import get_llm\n",
    "from python.ai_core.prompts import def_prompt\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    the_joke: str = Field(description=\"a good joke\")\n",
    "    explanation: str = Field(description=\"explain why it's funny\")\n",
    "    rate: float = Field(description=\"rate how the joke is funny between 0 and 5\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt_with_format = \"\"\"\n",
    "    tell me  a joke on {topic}     \n",
    "    --- \n",
    "    {format_instructions}\"\"\"\n",
    "\n",
    "structured_prompt = def_prompt(user=prompt_with_format).partial(\n",
    "    format_instructions=parser.get_format_instructions(),\n",
    ")\n",
    "\n",
    "LLM_ID = None\n",
    "structured_joke = structured_prompt | get_llm(llm_id=LLM_ID) | parser\n",
    "\n",
    "r = structured_joke.invoke({\"topic\": \"cat\"})\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_378732/2639052080.py:1 <module>\n",
      "    structured_prompt: ChatPromptTemplate(\n",
      "        input_variables=['topic'],\n",
      "        partial_variables={\n",
      "            'format_instructions': (\n",
      "                'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n'\n",
      "                '\\n'\n",
      "                'As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strin'\n",
      "                'gs\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\n'\n",
      "                'the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"propertie'\n",
      "                's\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n'\n",
      "                '\\n'\n",
      "                'Here is the output schema:\\n'\n",
      "                '```\\n'\n",
      "                '{\"properties\": {\"the_joke\": {\"title\": \"The Joke\", \"description\": \"a good joke\", \"type\": \"string\"}, \"e'\n",
      "                'xplanation\": {\"title\": \"Explanation\", \"description\": \"explain why it\\'s funny\", \"type\": \"string\"}, \"ra'\n",
      "                'te\": {\"title\": \"Rate\", \"description\": \"rate how the joke is funny between 0 and 5\", \"type\": \"number\"}'\n",
      "                '}, \"required\": [\"the_joke\", \"explanation\", \"rate\"]}\\n'\n",
      "                '```'\n",
      "            ),\n",
      "        },\n",
      "        messages=[\n",
      "            HumanMessagePromptTemplate(\n",
      "                prompt=PromptTemplate(\n",
      "                    input_variables=[\n",
      "                        'format_instructions',\n",
      "                        'topic',\n",
      "                    ],\n",
      "                    template=(\n",
      "                        'tell me  a joke on {topic}     \\n'\n",
      "                        '--- \\n'\n",
      "                        '{format_instructions}'\n",
      "                    ),\n",
      "                ),\n",
      "            ),\n",
      "        ],\n",
      "    ) (ChatPromptTemplate) len=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['topic'], partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"the_joke\": {\"title\": \"The Joke\", \"description\": \"a good joke\", \"type\": \"string\"}, \"explanation\": {\"title\": \"Explanation\", \"description\": \"explain why it\\'s funny\", \"type\": \"string\"}, \"rate\": {\"title\": \"Rate\", \"description\": \"rate how the joke is funny between 0 and 5\", \"type\": \"number\"}}, \"required\": [\"the_joke\", \"explanation\", \"rate\"]}\\n```'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'topic'], template='tell me  a joke on {topic}     \\n--- \\n{format_instructions}'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug(structured_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tell me  a joke on cat     \n",
      "--- \n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"the_joke\": {\"title\": \"The Joke\", \"description\": \"a good joke\", \"type\": \"string\"}, \"explanation\": {\"title\": \"Explanation\", \"description\": \"explain why it's funny\", \"type\": \"string\"}, \"rate\": {\"title\": \"Rate\", \"description\": \"rate how the joke is funny between 0 and 5\", \"type\": \"number\"}}, \"required\": [\"the_joke\", \"explanation\", \"rate\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# You can have a look at the generated prompt:\n",
    "print(structured_prompt.invoke({\"topic\": \"cat\"}).messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method #2 : Use \"with_structured_output\"  (bases on function calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-04 10:54:39.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpython.ai_core.llm\u001b[0m:\u001b[36mget_llm\u001b[0m:\u001b[36m319\u001b[0m - \u001b[1mget LLM:'gpt_4_azure' -configurable: False - streaming: False\u001b[0m\n",
      "\u001b[32m2024-09-04 10:54:39.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpython.ai_core.cache\u001b[0m:\u001b[36mset_cache\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mLLM cache : SQLiteCache\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_378732/925907821.py:6 <module>\n",
      "    chain.invoke(({\"topic\": \"cat\"})): Joke(\n",
      "        the_joke='Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!',\n",
      "        explanation=(\n",
      "            \"This joke is a play on words. In the context of computers, a 'mouse' is a device used to navigate the int\"\n",
      "            'erface. However, cats are known for chasing and watching mice, which are small rodents. The humor comes f'\n",
      "            \"rom the double meaning of the word 'mouse' and the image of a cat literally sitting on a computer to watc\"\n",
      "            'h a computer mouse, as if it were a real mouse.'\n",
      "        ),\n",
      "        rate=3.0,\n",
      "    ) (Joke)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(the_joke='Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!', explanation=\"This joke is a play on words. In the context of computers, a 'mouse' is a device used to navigate the interface. However, cats are known for chasing and watching mice, which are small rodents. The humor comes from the double meaning of the word 'mouse' and the image of a cat literally sitting on a computer to watch a computer mouse, as if it were a real mouse.\", rate=3.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"tell me  a joke on {topic}\"\n",
    "\n",
    "# MODEL = None\n",
    "MODEL = \"gpt_4_azure\"\n",
    "chain = def_prompt(prompt) | get_llm(llm_id=MODEL).with_structured_output(Joke)\n",
    "debug(chain.invoke(({\"topic\": \"cat\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Assignement (Optional)\n",
    "Rate the above joke.\n",
    "Use https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/types/enum/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class JokeRater(Enum):\n",
    "    NOT_SO_GOOD = 0\n",
    "    GOOD = 1\n",
    "    VERY_GOOD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-training-2X6HL8i2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
